{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Web Scraping Lab\n",
    "\n",
    "In this lab you will first learn the following code snippet which is a simple web spider class that allows you to scrape paginated webpages. Read the code, run it, and make sure you understand how it works. In the challenges of this lab, we will guide you in building up this class so that eventually you will have a more robust web spider that you can further work on in the Web Scraping Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n",
      "[\"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', \"“If you can't explain it to a six year old, you don't understand it yourself.”\", \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', '“Life is what happens to us while we are making other plans.”']\n",
      "['“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”', '“For every minute you are angry you lose sixty seconds of happiness.”', '“If you judge people, you have no time to love them.”', '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', '“Today you are You, that is truer than true. There is no one alive who is Youer than You.”', '“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”', '“It is impossible to live without failing at something, unless you live so cautiously that you might as well not have lived at all - in which case, you fail by default.”', '“Logic will get you from A to Z; imagination will get you everywhere.”', '“One good thing about music, when it hits you, you feel no pain.”']\n",
      "[\"“The more that you read, the more things you will know. The more that you learn, the more places you'll go.”\", '“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?”', '“The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.”', '“Not all of us can do great things. But we can do small things with great love.”', '“To the well-organized mind, death is but the next great adventure.”', \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", \"“We read to know we're not alone.”\", '“Any fool can know. The point is to understand.”', '“I have always imagined that Paradise will be a kind of library.”', '“It is never too late to be what you might have been.”']\n",
      "['“A reader lives a thousand lives before he dies, said Jojen. The man who never reads lives only one.”', '“You can never get a cup of tea large enough or a book long enough to suit me.”', '“You believe lies so you eventually learn to trust no one but yourself.”', '“If you can make a woman laugh, you can make her do anything.”', '“Life is like riding a bicycle. To keep your balance, you must keep moving.”', '“The real lover is the man who can thrill you by kissing your forehead or smiling into your eyes or just staring into space.”', \"“A wise girl kisses but doesn't love, listens but doesn't believe, and leaves before she is left.”\", '“Only in the darkness can you see the stars.”', '“It matters not what someone is born, but what they grow to be.”', '“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”']\n",
      "['“There is nothing I would not do for those who are really my friends. I have no notion of loving people by halves, it is not my nature.”', '“Do one thing every day that scares you.”', '“I am good, but not an angel. I do sin, but I am not the devil. I am just a small girl in a big world trying to find someone to love.”', '“If I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.”', '“If you only read the books that everyone else is reading, you can only think what everyone else is thinking.”', '“The difference between genius and stupidity is: genius has its limits.”', \"“He's like a drug for you, Bella.”\", '“There is no friend as loyal as a book.”', '“When one door of happiness closes, another opens; but often we look so long at the closed door that we do not see the one which has been opened for us.”', \"“Life isn't about finding yourself. Life is about creating yourself.”\"]\n",
      "[\"“That's the problem with drinking, I thought, as I poured myself a drink. If something bad happens you drink in an attempt to forget; if something good happens you drink in order to celebrate; and if nothing happens you drink to make something happen.”\", '“You don’t forget the face of the person who was your last hope.”', \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", '“To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.”', '“Not all those who wander are lost.”', '“Do not pity the dead, Harry. Pity the living, and, above all those who live without love.”', '“There is nothing to writing. All you do is sit down at a typewriter and bleed.”', '“Finish each day and be done with it. You have done what you could. Some blunders and absurdities no doubt crept in; forget them as soon as you can. Tomorrow is a new day. You shall begin it serenely and with too high a spirit to be encumbered with your old nonsense.”', '“I have never let my schooling interfere with my education.”', \"“I have heard there are troubles of more than one kind. Some come from ahead and some come from behind. But I've bought a big bat. I'm all ready you see. Now my troubles are going to have troubles with me!”\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“If I had a flower for every time I thought of you...I could walk through my garden forever.”', '“Some people never go crazy. What truly horrible lives they must lead.”', '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', \"“What really knocks me out is a book that, when you're all done reading it, you wish the author that wrote it was a terrific friend of yours and you could call him up on the phone whenever you felt like it. That doesn't happen much, though.”\", '“The reason I talk to myself is because I’m the only one whose answers I accept.”', \"“You may say I'm a dreamer, but I'm not the only one. I hope someday you'll join us. And the world will live as one.”\", '“I am free of all prejudice. I hate everyone equally. ”', \"“The question isn't who is going to let me; it's who is going to stop me.”\", \"“′Classic′ - a book which people praise and don't read.”\"]\n",
      "['“Anyone who has never made a mistake has never tried anything new.”', \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", '“Remember, if the time should come when you have to make a choice between what is right and what is easy, remember what happened to a boy who was good, and kind, and brave, because he strayed across the path of Lord Voldemort. Remember Cedric Diggory.”', '“I declare after all there is no enjoyment like reading! How much sooner one tires of any thing than of a book! -- When I have a house of my own, I shall be miserable if I have not an excellent library.”', '“There are few people whom I really love, and still fewer of whom I think well. The more I see of the world, the more am I dissatisfied with it; and every day confirms my belief of the inconsistency of all human characters, and of the little dependence that can be placed on the appearance of merit or sense.”', '“Some day you will be old enough to start reading fairy tales again.”', '“We are not necessarily doubting that God will do the best for us; we are wondering how painful the best will turn out to be.”', '“The fear of death follows from the fear of life. A man who lives fully is prepared to die at any time.”', '“A lie can travel half way around the world while the truth is putting on its shoes.”', '“I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.”']\n",
      "['“The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing, and should therefore be treated with great caution.”', \"“I'm the one that's got to die when it's time for me to die, so let me live my life the way I want to.”\", '“To die will be an awfully big adventure.”', '“It takes courage to grow up and become who you really are.”', '“But better to get hurt by the truth than comforted with a lie.”', '“You never really understand a person until you consider things from his point of view... Until you climb inside of his skin and walk around in it.”', '“You have to write the book that wants to be written. And if the book will be too difficult for grown-ups, then you write it for children.”', '“Never tell the truth to people who are not worthy of it.”', \"“A person's a person, no matter how small.”\", '“... a mind needs books as a sword needs a whetstone, if it is to keep its edge.”']\n"
     ]
    }
   ],
   "source": [
    "#IronhackSpider for challenge 1,2,3,4 + bonus challenge1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_random_headers(self):\n",
    "\n",
    "        headers_random_list=[\"Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail appname/appversion\",\n",
    "        \"Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail Firefox/firefoxversion appname/appversion\",\n",
    "        \"Mozilla/5.0 (Android 4.4; Mobile; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "        \"Mozilla/5.0 (Android 4.4; Tablet; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "        \"Mozilla/5.0 (Windows NT x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (Windows NT x.y; Win64; x64; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (Macintosh; PPC Mac OS X x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (X11; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "        \"Mozilla/5.0 (Maemo; Linux armv7l; rv:10.0) Gecko/20100101 Firefox/10.0 Fennec/10.0\",\n",
    "        \"Mozilla/5.0 (Android; Mobile; rv:40.0) Gecko/40.0 Firefox/40.0\",\n",
    "        \"Mozilla/5.0 (Android; Tablet; rv:40.0) Gecko/40.0 Firefox/40.0\",\n",
    "        \"Mozilla/5.0 (Android 4.4; Mobile; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "        \"Mozilla/5.0 (Android 4.4; Tablet; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "        \"Mozilla/5.0 (Linux; Android 7.0) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/1.0 Chrome/59.0.3029.83 Mobile Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Linux; Android 7.0) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/1.0 Chrome/59.0.3029.83 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Android 7.0; Mobile; rv:62.0) Gecko/62.0 Firefox/62.0\",\n",
    "        \"Mozilla/5.0 (iPhone; CPU iPhone OS 12_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/7.0.4 Mobile/16B91 Safari/605.1.15\",\n",
    "        \"Mozilla/5.0 (Linux; Android 7.1.2) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/3.0 Chrome/59.0.3017.125 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Mobile; rv:26.0) Gecko/26.0 Firefox/26.0\",\n",
    "        \"Mozilla/5.0 (Tablet; rv:26.0) Gecko/26.0 Firefox/26.0\",\n",
    "        \"Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\",\n",
    "        \"Mozilla/5.0 (iPad; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\",\n",
    "        \"Mozilla/5.0 (Maemo; Linux armv7l; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 Fennec/10.0.1\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.5; rv:2.0.1) Gecko/20100101 Firefox/4.0.1 Camino/2.2.1\",\n",
    "        \"Mozilla/5.0 (Windows NT 5.2; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.5; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\",\n",
    "        \"Mozilla/5.0 (X11; Linux i686; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\"]\n",
    "\n",
    "        return random.choice(headers_random_list)\n",
    "\n",
    "    \n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            \n",
    "            user_agent = self.get_random_headers()\n",
    "            headers = {'user-agent': user_agent}\n",
    "            \n",
    "            response = requests.get(url, headers=headers, verify=True, timeout=5)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            result = self.content_parser(response.content)\n",
    "            self.output_results(result)\n",
    "\n",
    "        except requests.exceptions.HTTPError as HTTPError:\n",
    "            print (\"Http Error:\",HTTPError)\n",
    "        except requests.exceptions.ConnectionError as ConnectionError:\n",
    "            print (\"Error Connecting:\",ConnectionError)\n",
    "        except requests.exceptions.Timeout as TimeoutError:\n",
    "            print (\"Timeout Error:\",TimeoutError)\n",
    "        except requests.exceptions.TooManyRedirects as TooManyRedirectsError:\n",
    "            print (\"Too Many Redirects:\",TooManyRedirectsError)\n",
    "        except requests.exceptions.RequestException as OtherError:\n",
    "            print (\"Oops! You have an Error\",OtherError)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "            if self.sleep_interval >0:\n",
    "                time.sleep(5)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 10 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    quotes_class= soup.find_all(class_=\"text\")\n",
    "    \n",
    "    quotes=[]\n",
    "    for info in quotes_class:\n",
    "        quote=info.get_text()\n",
    "        quotes.append(quote)\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1 - Custom Parser Function\n",
    "\n",
    "In this challenge, complete the custom `quotes_parser()` function so that the returned result contains the quote string instead of the whole html page content.\n",
    "\n",
    "In the cell below, write your updated `quotes_parser()` function and kickstart the spider. Make sure the results being printed contain a list of quote strings extracted from the html content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def quotes_parser(content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    quotes_class= soup.find_all(class_=\"text\")\n",
    "    \n",
    "    quotes=[]\n",
    "    for info in quotes_class:\n",
    "        quote=info.get_text()\n",
    "        quotes.append(quote)\n",
    "    \n",
    "    return quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 - Error Handling\n",
    "\n",
    "In `IronhackSpider.scrape_url()`, catch any error that might occur when you make requests to scrape the webpage. This includes checking the response status code and catching http request errors such as timeout, SSL, and too many redirects.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def scrape_url(self, url):\n",
    "    try:\n",
    "        response = requests.get(url, verify=True, timeout=4)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "\n",
    "    except requests.exceptions.HTTPError as HTTPError:\n",
    "        print (\"Http Error:\",HTTPError)\n",
    "    except requests.exceptions.ConnectionError as ConnectionError:\n",
    "        print (\"Error Connecting:\",ConnectionError)\n",
    "    except requests.exceptions.Timeout as TimeoutError:\n",
    "        print (\"Timeout Error:\",TimeoutError)\n",
    "    except requests.exceptions.TooManyRedirects as TooManyRedirectsError:\n",
    "        print (\"Too Many Redirects:\",TooManyRedirectsError)\n",
    "    except requests.exceptions.RequestException as OtherError:\n",
    "        print (\"Oops! You have an Error\",OtherError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Sleep Interval\n",
    "\n",
    "In `IronhackSpider.kickstart()`, implement `sleep_interval`. You will check if `self.sleep_interval` is larger than 0. If so, tell the FOR loop to sleep the given amount of time before making the next request.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def kickstart(self):\n",
    "    for i in range(1, self.pages_to_scrape+1):\n",
    "        self.scrape_url(self.url_pattern % i)\n",
    "        \n",
    "        if sleep_interval >0:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Test Batch Scraping\n",
    "\n",
    "Change the `PAGES_TO_SCRAPE` value from `1` to `10`. Try if your code still works as intended to scrape 10 webpages. If there are errors in your code, fix them.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "PAGES_TO_SCRAPE = 10 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Scrape a Different Website\n",
    "\n",
    "Update the parameters passed to the `IronhackSpider` constructor so that you coder can crawl [books.toscrape.com](http://books.toscrape.com/). You will need to use a different `URL_PATTERN` (figure out the new url pattern by yourself) and write another parser function to be passed to `IronhackSpider`. \n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'A Light in the Attic', None, 'Tipping the Velvet', None, 'Soumission', None, 'Sharp Objects', None, 'Sapiens: A Brief History of Humankind', None, 'The Requiem Red', None, 'The Dirty Little Secrets of Getting Your Dream Job', None, 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', None, 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', None, 'The Black Maria', None, 'Starving Hearts (Triangular Trade Trilogy, #1)', None, \"Shakespeare's Sonnets\", None, 'Set Me Free', None, \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", None, 'Rip it Up and Start Again', None, 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', None, 'Olio', None, 'Mesaerion: The Best Science Fiction Stories 1800-1849', None, 'Libertarianism for Beginners', None, \"It's Only the Himalayas\", None]\n"
     ]
    }
   ],
   "source": [
    "#IronhackSpider including only challenge 5\n",
    "\n",
    "# your code here\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, verify=True, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            result = self.content_parser(response.content)\n",
    "            self.output_results(result)\n",
    "\n",
    "        except requests.exceptions.HTTPError as HTTPError:\n",
    "            print (\"Http Error:\",HTTPError)\n",
    "        except requests.exceptions.ConnectionError as ConnectionError:\n",
    "            print (\"Error Connecting:\",ConnectionError)\n",
    "        except requests.exceptions.Timeout as TimeoutError:\n",
    "            print (\"Timeout Error:\",TimeoutError)\n",
    "        except requests.exceptions.TooManyRedirects as TooManyRedirectsError:\n",
    "            print (\"Too Many Redirects:\",TooManyRedirectsError)\n",
    "        except requests.exceptions.RequestException as OtherError:\n",
    "            print (\"Oops! You have an Error\",OtherError)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "            if self.sleep_interval >0:\n",
    "                time.sleep(5)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html' # regex pattern for the urls to scrape\n",
    "\n",
    "#cambiar a 20 paginas!! pero lo dejo así para combrobar\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup= BeautifulSoup(content, 'html.parser')\n",
    "    #debería añadir que a fuera solo de la class=image_container pero me da error.\n",
    "    quotes_class= soup.find_all(\"a\")\n",
    "    \n",
    "    \n",
    "    quotes=[]\n",
    "    for info in quotes_class:\n",
    "        quote= info.get(\"title\")\n",
    "        quotes.append(quote)\n",
    "    \n",
    "    return quotes\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Making Your Spider Unblockable\n",
    "\n",
    "Use techniques such as randomizing user agents and referers in your requests to reduce the likelihood that your spider is blocked by websites. [Here](http://blog.adnansiddiqi.me/5-strategies-to-write-unblock-able-web-scrapers-in-python/) is a great article to learn these techniques.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def get_random_headers(self):\n",
    "\n",
    "    headers_random_list=[\"Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail appname/appversion\",\n",
    "    \"Mozilla/5.0 (platform; rv:geckoversion) Gecko/geckotrail Firefox/firefoxversion appname/appversion\",\n",
    "    \"Mozilla/5.0 (Android 4.4; Mobile; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "    \"Mozilla/5.0 (Android 4.4; Tablet; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "    \"Mozilla/5.0 (Windows NT x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (Windows NT x.y; Win64; x64; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; PPC Mac OS X x.y; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0\",\n",
    "    \"Mozilla/5.0 (Maemo; Linux armv7l; rv:10.0) Gecko/20100101 Firefox/10.0 Fennec/10.0\",\n",
    "    \"Mozilla/5.0 (Android; Mobile; rv:40.0) Gecko/40.0 Firefox/40.0\",\n",
    "    \"Mozilla/5.0 (Android; Tablet; rv:40.0) Gecko/40.0 Firefox/40.0\",\n",
    "    \"Mozilla/5.0 (Android 4.4; Mobile; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "    \"Mozilla/5.0 (Android 4.4; Tablet; rv:41.0) Gecko/41.0 Firefox/41.0\",\n",
    "    \"Mozilla/5.0 (Linux; Android 7.0) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/1.0 Chrome/59.0.3029.83 Mobile Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Linux; Android 7.0) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/1.0 Chrome/59.0.3029.83 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Android 7.0; Mobile; rv:62.0) Gecko/62.0 Firefox/62.0\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 12_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) FxiOS/7.0.4 Mobile/16B91 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Linux; Android 7.1.2) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Focus/3.0 Chrome/59.0.3017.125 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Mobile; rv:26.0) Gecko/26.0 Firefox/26.0\",\n",
    "    \"Mozilla/5.0 (Tablet; rv:26.0) Gecko/26.0 Firefox/26.0\",\n",
    "    \"Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\",\n",
    "    \"Mozilla/5.0 (iPad; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\",\n",
    "    \"Mozilla/5.0 (Maemo; Linux armv7l; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 Fennec/10.0.1\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.5; rv:2.0.1) Gecko/20100101 Firefox/4.0.1 Camino/2.2.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 5.2; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.5; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\",\n",
    "    \"Mozilla/5.0 (X11; Linux i686; rv:10.0.1) Gecko/20100101 Firefox/10.0.1 SeaMonkey/2.7.1\"]\n",
    "\n",
    "    return random.choice(headers_random_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will be add in def scrape_url(self, url):\n",
    "\n",
    "user_agent = get_random_header()\n",
    "headers = {'user-agent': user_agent}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
